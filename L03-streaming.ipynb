{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4b7bca",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"500\">\n",
    "\n",
    "Streaming reduces the latency between generating data and user receiving them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987fb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"ollama:gpt-oss:20b-cloud\",\n",
    "    system_prompt=\"You are a full-stack comedian.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f5b5d",
   "metadata": {},
   "source": [
    "### No Streaming - Invoke\n",
    "\n",
    "No streaming - everything once completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07fbfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why donâ€™t skeletons fight each other?\n",
      "\n",
      "They donâ€™t have the guts!\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke.\"}\n",
    "    ]}\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed498a8f",
   "metadata": {},
   "source": [
    "### Values\n",
    "\n",
    "Stream message by message - Eg: First human message. After that AI message..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2153edf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why donâ€™t skeletons fight each other?  \n",
      "\n",
      "They donâ€™t have the guts. ðŸ‘»ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "for step in agent.stream(\n",
    "    {\"messages\":[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a dad joke\"}\n",
    "    ]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa87a32",
   "metadata": {},
   "source": [
    "### Messages\n",
    "\n",
    "Messages stream data token by token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddeb2b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**A Picnic Under the Sun**\n",
      "\n",
      "We gather round a blanket, warm and soft,  \n",
      "With sandwiches, lemonade, and a loaf of love.  \n",
      "The kids giggle as the kites start to rise,  \n",
      "Above their heads, a gentle summer sky.\n",
      "\n",
      "A robin sings the anthem of bright new days,  \n",
      "While squirrels trade acorns in the trees' bright blaze.  \n",
      "We share stories, jokes, and a slice of pie,  \n",
      "Under the canopy of clouds drifting by.\n",
      "\n",
      "Evening whispers, stars peek to greet,  \n",
      "We fold the day, tucked beneath the warm, blue seat.  \n",
      "With hearts full of joy, we dream of tomorrowâ€”  \n",
      "A familyâ€™s simple, sweet, bright, sunlit sorrow."
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\":[\n",
    "        {\"role\": \"user\", \"content\": \"Write a family friendly poem\"}\n",
    "    ]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f6925",
   "metadata": {},
   "source": [
    "### Streaming in Tools\n",
    "\n",
    "We can deliver information to user even before the final result is ready via streaming. In tools, we can provide status information to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77187b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content=\"What's the weather like in San Francisco?\", additional_kwargs={}, response_metadata={}, id='09f8e523-f3d0-4372-915b-3fe65612a519')]})\n",
      "('values', {'messages': [HumanMessage(content=\"What's the weather like in San Francisco?\", additional_kwargs={}, response_metadata={}, id='09f8e523-f3d0-4372-915b-3fe65612a519'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b-cloud', 'created_at': '2025-10-31T06:23:19.184269294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 489759739, 'load_duration': None, 'prompt_eval_count': 128, 'prompt_eval_duration': None, 'eval_count': 40, 'eval_duration': None, 'model_name': 'gpt-oss:20b-cloud', 'model_provider': 'ollama'}, id='lc_run--2776bccf-1e2e-46fc-916f-e2fe68464745-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': '4680a903-3ed6-48d0-933b-0bc5ccdad740', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 40, 'total_tokens': 168})]})\n",
      "('custom', 'Fetching weather information for San Francisco...\\n')\n",
      "('custom', 'Fetched data from weather API for San Francisco...\\n')\n",
      "('values', {'messages': [HumanMessage(content=\"What's the weather like in San Francisco?\", additional_kwargs={}, response_metadata={}, id='09f8e523-f3d0-4372-915b-3fe65612a519'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b-cloud', 'created_at': '2025-10-31T06:23:19.184269294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 489759739, 'load_duration': None, 'prompt_eval_count': 128, 'prompt_eval_duration': None, 'eval_count': 40, 'eval_duration': None, 'model_name': 'gpt-oss:20b-cloud', 'model_provider': 'ollama'}, id='lc_run--2776bccf-1e2e-46fc-916f-e2fe68464745-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': '4680a903-3ed6-48d0-933b-0bc5ccdad740', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 40, 'total_tokens': 168}), ToolMessage(content='The weather in San Francisco is sunny with a high of 25Â°C.', name='get_weather', id='a615781a-e8e7-4b00-b91e-6a97fb27e21c', tool_call_id='4680a903-3ed6-48d0-933b-0bc5ccdad740')]})\n",
      "('values', {'messages': [HumanMessage(content=\"What's the weather like in San Francisco?\", additional_kwargs={}, response_metadata={}, id='09f8e523-f3d0-4372-915b-3fe65612a519'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b-cloud', 'created_at': '2025-10-31T06:23:19.184269294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 489759739, 'load_duration': None, 'prompt_eval_count': 128, 'prompt_eval_duration': None, 'eval_count': 40, 'eval_duration': None, 'model_name': 'gpt-oss:20b-cloud', 'model_provider': 'ollama'}, id='lc_run--2776bccf-1e2e-46fc-916f-e2fe68464745-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': '4680a903-3ed6-48d0-933b-0bc5ccdad740', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 40, 'total_tokens': 168}), ToolMessage(content='The weather in San Francisco is sunny with a high of 25Â°C.', name='get_weather', id='a615781a-e8e7-4b00-b91e-6a97fb27e21c', tool_call_id='4680a903-3ed6-48d0-933b-0bc5ccdad740'), AIMessage(content='The weather in San\\u202fFrancisco is sunny with a high of\\u202f25\\u202fÂ°C.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b-cloud', 'created_at': '2025-10-31T06:23:23.250512306Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3684166047, 'load_duration': None, 'prompt_eval_count': 176, 'prompt_eval_duration': None, 'eval_count': 22, 'eval_duration': None, 'model_name': 'gpt-oss:20b-cloud', 'model_provider': 'ollama'}, id='lc_run--062261bb-3fff-47e5-b344-2ca1f281c416-0', usage_metadata={'input_tokens': 176, 'output_tokens': 22, 'total_tokens': 198})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather information for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "\n",
    "    writer(f\"Fetching weather information for {city}...\\n\")\n",
    "    writer(f\"Fetched data from weather API for {city}...\\n\")\n",
    "\n",
    "    return f\"The weather in {city} is sunny with a high of 25Â°C.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"ollama:gpt-oss:20b-cloud\",\n",
    "    system_prompt=\"You are a helpful assistant that provides weather information.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\":[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}\n",
    "    ]},\n",
    "    stream_mode=[\"values\",\"custom\"],\n",
    "):\n",
    "    print(chunk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c9f1999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Fetching weather information for SF...\\n')\n",
      "('custom', 'Fetched data from weather API for SF...\\n')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\":[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like in SF?\"}\n",
    "    ]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(f\"{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65d89a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather information for San Francisco...\n",
      "Fetched data from weather API for San Francisco...\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\":[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like in SF?\"}\n",
    "    ]},\n",
    "    stream_mode=[\"values\",\"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(f\"{chunk[1]}\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-essentials-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
